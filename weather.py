# -*- coding: utf-8 -*-
"""Weather.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1052e-vX8u3-wTYhll5cKH890oi_Z0PuT
"""

import sqlite3
import pandas as pd
# Create your connection.
cnx = sqlite3.connect('test.db')

df = pd.read_sql_query("SELECT * FROM TIME_TABLE;", cnx)

display(df)



avg_df=df.loc[df['ID'] == 7]
true_df=df.loc[df['ID'] == 2]

avg_df.reset_index(drop=True, inplace=True)
true_df.reset_index(drop=True, inplace=True)
avg_df

# Select the 'TEMP' column from true_df and rename it to 'TrueTemp'
true_temp = true_df['TEMP'].rename('TrueTemp')
true_humidity = true_df['HUMIDITY'].rename('TrueHumidity')
true_press = true_df['PRESS'].rename('TruePress')
true_rain = true_df['RAIN_1'].rename('TrueRain')

# Concatenate avg_df and true_temp along axis 1 (columns)
avg_df = pd.concat([avg_df, true_temp], axis=1)
avg_df = pd.concat([avg_df, true_humidity], axis=1)
avg_df = pd.concat([avg_df, true_press], axis=1)
avg_df = pd.concat([avg_df, true_rain], axis=1)

display(avg_df)

avg_df.describe()

# prompt: create a dataframe called trimmed df which only contains every fourth row

trimmed_df = avg_df[avg_df.index % 12 == 0]
trimmed_df

# prompt: drop rows TIME, ID,RAIN_3,SNOW_3,SNOW_1,SEA_LEV,GND_LEV,STAMP

trimmed_df = trimmed_df.drop(columns=['TIME', 'ID','RAIN_3','SNOW_3','SNOW_1','SEA_LEV','GND_LEV','STAMP','TEMP_MAX','TEMP_MIN','VISIBILITY','WIND_DEG','WIND_SPEED','WIND_GUST'])
trimmed_df

# prompt: Create a pytorch model to predict TrueRain based on past values, split into train and test datasets

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
import numpy as np

# Define a custom dataset class
class RainDataset(Dataset):
    def __init__(self, df):
        self.data = df[['TEMP', 'HUMIDITY', 'PRESS', 'TrueTemp', 'RAIN_1', 'TrueHumidity', 'TruePress', 'TrueRain']].values

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        features = torch.tensor(self.data[idx, :-1], dtype=torch.float32)
        target = torch.tensor(self.data[idx, -1], dtype=torch.float32)
        return features, target

# Create a PyTorch model
class RainPredictor(nn.Module):
    def __init__(self):
        super(RainPredictor, self).__init__()
        self.fc1 = nn.Linear(7, 32)
        self.fc2 = nn.Linear(32, 16)
        self.fc3 = nn.Linear(16, 1)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Prepare the data
dataset = RainDataset(trimmed_df)

# Split the data into training and testing sets
train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)

# Create data loaders
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Initialize the model, loss function, and optimizer
model = RainPredictor()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
num_epochs = 100
for epoch in range(num_epochs):
    for features, target in train_loader:
        optimizer.zero_grad()
        outputs = model(features)
        loss = criterion(outputs, target.unsqueeze(1))
        loss.backward()
        optimizer.step()
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Evaluate the model
with torch.no_grad():
    total_loss = 0
    for features, target in test_loader:
        outputs = model(features)
        loss = criterion(outputs, target.unsqueeze(1))
        total_loss += loss.item()
    avg_loss = total_loss / len(test_loader)
    print(f'Test Loss: {avg_loss:.4f}')

# prompt: plot the predicted values of test_loader against values of trueRain

import matplotlib.pyplot as plt

with torch.no_grad():
    predictions = []
    true_values = []
    for features, target in test_loader:
        outputs = model(features)
        predictions.extend(outputs.numpy().flatten())
        true_values.extend(target.numpy())

# Plot the predictions against true values
plt.scatter(true_values, predictions)
plt.plot([0,1, 2, 4, 25], [0,1, 2, 4, 25],color='red')
plt.xlabel("True Rain")
plt.ylabel("Predicted Rain")
plt.title("Rain Prediction")
plt.show()

deltas=[]
for i in range(len(predictions)):
  deltas.append(predictions[i]-true_values[i])

print(sum(deltas)/len(deltas))